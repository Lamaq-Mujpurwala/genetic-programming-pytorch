# ğŸ§¬ Evolving Neural Network Crossover Operators using Genetic Programming

This project is a **from-scratch implementation** of the research paper on *GP-evolved crossover operators for Genetic Algorithms optimizing Neural Network weights*. It explores how **Genetic Programming (GP)** can evolve **custom crossover operators** to enhance **Genetic Algorithms (GA)** for training neural networks â€” combining deep learning and evolutionary computation.

> âš ï¸ This repository is not a reproduction, but an **independent re-implementation and analysis** of the methodology from the referenced research.

---

## ğŸš€ Features

- âœ… Complete Genetic Algorithm (GA) to evolve Neural Network weights
- âœ… Fully functional Genetic Programming (GP) engine to evolve crossover operators
- âœ… Support for both **reusable** and **disposable** crossover strategies
- âœ… Implemented with the powerful [`DEAP`](https://github.com/DEAP/deap) library
- âœ… Neural networks built and accelerated using **PyTorch + CUDA**
- âœ… Manual **bloat control**, crossover validation, and evolutionary metrics tracking
- âœ… Experiment 2 replicated: **GA w/o crossover vs GA w/ evolved crossover**

---

## ğŸ§  What This Project Covers

### ğŸ“š Research Understanding
- Deep dive into the paperâ€™s methodology
- Mathematical insight into crossover fitness and GP evolution logic

### ğŸ§¬ Evolutionary Computing
- Mutation, tournament selection, elitism
- GP primitives and terminals customized for NN weight vectors
- Safe and stable crossover operator evaluation

### ğŸ§  Deep Learning
- PyTorch-based neural network models
- Custom weight manipulation and evaluation
- Training-free evaluation using pre-initialized networks

---

## ğŸ› ï¸ Technologies Used

| Tool        | Purpose                            |
|-------------|-------------------------------------|
| **Python**  | Core language                       |
| **DEAP**    | Genetic Algorithms & GP framework   |
| **PyTorch** | Neural network evaluation & GPU use |
| **WSL2**    | Linux-based setup for reproducibility |
| **CUDA**    | GPU acceleration                    |

---

## ğŸ“Š Experiments Replicated

- **Experiment 2** from the paper:
  - GA without crossover
  - GA with GP-evolved reusable crossover
  - Results compared over multiple seeds and datasets (e.g., Wine)

---

## ğŸ“ Structure

